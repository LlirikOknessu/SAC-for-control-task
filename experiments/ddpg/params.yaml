ddpg_params:
  experiment_params:
    learning_mode: 'model'
    simulation_time: 30.3
  additional_params:
    seed: 42  # random seed
    env_name: 'BallTube-v1'  # name of the environment with version
    render: 0  # set gym environment to render display
    verbose: 0  # log execution details
    start_steps: 0  # number of global steps before random exploration ends
  general_params:
    model_name: 'sac_m_v0' # name of the saved model
    math_model_address: '10.24.1.206'
    math_model_port: 5000
    model_observation: 4
    model_action_space: 1
    discretization_step: 0.1
    y_target_mode: 'fixed'
    y_target: 0.8
    MOVING_AVERAGE_WINDOW: 100
  neural_network_params:
    batch_size: 256  # minibatch sample size for training
    gamma: 0.9  # discount factor for future rewards
    alpha: 0.001 # learning rate for actor
    beta: 0.002 # learning rate for critic
    tau: 0.005 # soft update both actor and critic
    noise: 0.1
param_sweep:
  episode_limit: 10000
  sweep:
    layer_size: [32, 64, 128]
    batch_size: [32, 64, 128]
    alpha: [0.001, 0.0005, 0.0003]
    beta: [0.002, 0.001, 0.0006]